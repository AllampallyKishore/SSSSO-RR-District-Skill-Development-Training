{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16cb5b6",
   "metadata": {},
   "source": [
    "### Chat API : OpenAI\n",
    "Let's start with a direct API calls to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bc5d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.4\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.2.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached orjson-3.11.1-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached sqlalchemy-2.0.42-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Using cached greenlet-3.2.3-cp313-cp313-win_amd64.whl (297 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.10-py3-none-any.whl (372 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached orjson-3.11.1-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-extensions, tenacity, sniffio, PyYAML, orjson, jsonpointer, idna, h11, greenlet, charset_normalizer, certifi, annotated-types, typing-inspection, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ----------------------------------------  0/28 [zstandard]\n",
      "   ----------------------------------------  0/28 [zstandard]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   - --------------------------------------  1/28 [urllib3]\n",
      "   -- -------------------------------------  2/28 [typing-extensions]\n",
      "   -- -------------------------------------  2/28 [typing-extensions]\n",
      "   -- -------------------------------------  2/28 [typing-extensions]\n",
      "   ---- -----------------------------------  3/28 [tenacity]\n",
      "   ---- -----------------------------------  3/28 [tenacity]\n",
      "   ---- -----------------------------------  3/28 [tenacity]\n",
      "   ----- ----------------------------------  4/28 [sniffio]\n",
      "   ----- ----------------------------------  4/28 [sniffio]\n",
      "   ----- ----------------------------------  4/28 [sniffio]\n",
      "   ------- --------------------------------  5/28 [PyYAML]\n",
      "   ------- --------------------------------  5/28 [PyYAML]\n",
      "   ------- --------------------------------  5/28 [PyYAML]\n",
      "   ------- --------------------------------  5/28 [PyYAML]\n",
      "   -------- -------------------------------  6/28 [orjson]\n",
      "   -------- -------------------------------  6/28 [orjson]\n",
      "   ---------- -----------------------------  7/28 [jsonpointer]\n",
      "   ---------- -----------------------------  7/28 [jsonpointer]\n",
      "   ----------- ----------------------------  8/28 [idna]\n",
      "   ----------- ----------------------------  8/28 [idna]\n",
      "   ----------- ----------------------------  8/28 [idna]\n",
      "   ----------- ----------------------------  8/28 [idna]\n",
      "   ----------- ----------------------------  8/28 [idna]\n",
      "   ------------ ---------------------------  9/28 [h11]\n",
      "   ------------ ---------------------------  9/28 [h11]\n",
      "   ------------ ---------------------------  9/28 [h11]\n",
      "   ------------ ---------------------------  9/28 [h11]\n",
      "   -------------- ------------------------- 10/28 [greenlet]\n",
      "   -------------- ------------------------- 10/28 [greenlet]\n",
      "   -------------- ------------------------- 10/28 [greenlet]\n",
      "   -------------- ------------------------- 10/28 [greenlet]\n",
      "   -------------- ------------------------- 10/28 [greenlet]\n",
      "   --------------- ------------------------ 11/28 [charset_normalizer]\n",
      "   --------------- ------------------------ 11/28 [charset_normalizer]\n",
      "   --------------- ------------------------ 11/28 [charset_normalizer]\n",
      "   --------------- ------------------------ 11/28 [charset_normalizer]\n",
      "   --------------- ------------------------ 11/28 [charset_normalizer]\n",
      "   ----------------- ---------------------- 12/28 [certifi]\n",
      "   ----------------- ---------------------- 12/28 [certifi]\n",
      "   ------------------ --------------------- 13/28 [annotated-types]\n",
      "   ------------------ --------------------- 13/28 [annotated-types]\n",
      "   ------------------ --------------------- 13/28 [annotated-types]\n",
      "   -------------------- ------------------- 14/28 [typing-inspection]\n",
      "   -------------------- ------------------- 14/28 [typing-inspection]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   --------------------- ------------------ 15/28 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 16/28 [requests]\n",
      "   ---------------------- ----------------- 16/28 [requests]\n",
      "   ---------------------- ----------------- 16/28 [requests]\n",
      "   ---------------------- ----------------- 16/28 [requests]\n",
      "   ---------------------- ----------------- 16/28 [requests]\n",
      "   ------------------------ --------------- 17/28 [pydantic-core]\n",
      "   ------------------------ --------------- 17/28 [pydantic-core]\n",
      "   ------------------------ --------------- 17/28 [pydantic-core]\n",
      "   ------------------------- -------------- 18/28 [jsonpatch]\n",
      "   ------------------------- -------------- 18/28 [jsonpatch]\n",
      "   ------------------------- -------------- 18/28 [jsonpatch]\n",
      "   --------------------------- ------------ 19/28 [httpcore]\n",
      "   --------------------------- ------------ 19/28 [httpcore]\n",
      "   --------------------------- ------------ 19/28 [httpcore]\n",
      "   --------------------------- ------------ 19/28 [httpcore]\n",
      "   --------------------------- ------------ 19/28 [httpcore]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ---------------------------- ----------- 20/28 [anyio]\n",
      "   ------------------------------ --------- 21/28 [requests-toolbelt]\n",
      "   ------------------------------ --------- 21/28 [requests-toolbelt]\n",
      "   ------------------------------ --------- 21/28 [requests-toolbelt]\n",
      "   ------------------------------ --------- 21/28 [requests-toolbelt]\n",
      "   ------------------------------ --------- 21/28 [requests-toolbelt]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   ------------------------------- -------- 22/28 [pydantic]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   -------------------------------- ------- 23/28 [httpx]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ---------------------------------- ----- 24/28 [langsmith]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ----------------------------------- ---- 25/28 [langchain-core]\n",
      "   ------------------------------------- -- 26/28 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 26/28 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 26/28 [langchain-text-splitters]\n",
      "   ------------------------------------- -- 26/28 [langchain-text-splitters]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   -------------------------------------- - 27/28 [langchain]\n",
      "   ---------------------------------------- 28/28 [langchain]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.42 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.7.14 charset_normalizer-3.4.2 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.72 langchain-text-splitters-0.3.9 langsmith-0.4.10 orjson-3.11.1 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.23.0\n",
      "Collecting openai\n",
      "  Using cached openai-1.98.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.98.0-py3-none-any.whl (767 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------------------------------------- 0/4 [tqdm]\n",
      "   ---------- ----------------------------- 1/4 [jiter]\n",
      "   ---------- ----------------------------- 1/4 [jiter]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   -------------------- ------------------- 2/4 [distro]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai]\n",
      "   ---------------------------------------- 4/4 [openai]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.10.0 openai-1.98.0 tqdm-4.67.1\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e681a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set.\n",
      "1 + 1 equals 2.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# Read API key from environment variable\n",
    "# Ensure you have set the OPENAI_API_KEY in your .env file\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable in your .env file.\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is set.\")\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "print(get_completion(\"What is 1+1?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac85dcdb",
   "metadata": {},
   "source": [
    "Function to call the OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200842d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8c245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "prompt = \"What is 1+1?\"\n",
    "llm_response = get_completion(prompt)\n",
    "print(f\"LLM Response: {llm_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c5249a",
   "metadata": {},
   "source": [
    "Use Case : \n",
    "The below email is an example of a customer complaint.\n",
    "customer is angry and frustrated about the blender lid flying off and making a mess.\n",
    "The language used is informal and includes pirate slang.\n",
    "\n",
    "Exact english translation:\n",
    "I am very angry that the lid of my blender flew off and made a mess in my kitchen with smoothie! And to make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I need your help right now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68869496",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab46c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "\n",
    "prompt_to_llm = f\"\"\"Translate the text that is delimited by triple backticks into a style that is {output_style}. text: ```{customer_email}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25803e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would appreciate your assistance with this issue. Thank you.\n"
     ]
    }
   ],
   "source": [
    "llm_response_translation = get_completion(prompt_to_llm)\n",
    "print(f\"LLM Response Translation: {llm_response_translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d649013",
   "metadata": {},
   "source": [
    "LLM Response: I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c975250",
   "metadata": {},
   "source": [
    "### Chat API : LangChain\n",
    "Let's try how we can do the same using LangChain.\n",
    "\n",
    "- chatmodels have been moved to langchain-openai\n",
    "- Will be deprecated in future versions\n",
    "- Ensure you have the latest version of langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c327770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (0.4.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: langchain-community in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (0.4.10)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: langchain-openai in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-openai) (0.3.72)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-openai) (1.98.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      "Requirement already satisfied: colorama in e:\\sssso-rr-district-skill-development-training\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain \n",
    "!pip install langchain-community \n",
    "!pip install -U langchain-openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 equals 2.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "response = chat.invoke(\"What is 1+1?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f8b77",
   "metadata": {},
   "source": [
    "#### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8b1f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# prompt_to_llm = f\"\"\"Translate the text that is delimited by triple backticks into a style that is {output_style}. text: ```{customer_email}```\"\"\"\n",
    "# llm_response_translation = get_completion(prompt_to_llm)\n",
    "# print(f\"LLM Response Translation: {llm_response_translation}\")\n",
    "# ^^^^^^^^^^^^^^^^^^^ PREVIOUS CODE - WITHOUT LANGCHAIN ^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf51999",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "output_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "\n",
    "# No formatting needed for the template string. Observe that we did not use f-string here. Compare the following with prompt_to_llm above.\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {output_style}. \\\n",
    "text: ```{customer_email}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3a19daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('name', None)\n",
      "item: ('input_variables', ['customer_email', 'output_style'])\n",
      "item: ('optional_variables', [])\n",
      "item: ('input_types', {})\n",
      "item: ('output_parser', None)\n",
      "item: ('partial_variables', {})\n",
      "item: ('metadata', None)\n",
      "item: ('tags', None)\n",
      "item: ('messages', [HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['customer_email', 'output_style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {output_style}. text: ```{customer_email}```\\n'), additional_kwargs={})])\n",
      "item: ('validate_template', False)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "for item in prompt_template:\n",
    "    print(f\"item: {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc575a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Messages in the prompt template:\n",
      "item[0]: messages\n",
      "item[1]: [HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['customer_email', 'output_style'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {output_style}. text: ```{customer_email}```\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# Accessing the messages in the prompt template\n",
    "print(\"=\"*50)\n",
    "print(\"Messages in the prompt template:\")\n",
    "for item in prompt_template:\n",
    "    if item[0] == \"messages\":\n",
    "        print(f\"item[0]: {item[0]}\")\n",
    "        print(f\"item[1]: {item[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b4a617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prompt_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e5e4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['customer_email', 'output_style'] input_types={} partial_variables={} template='Translate the text that is delimited by triple backticks into a style that is {output_style}. text: ```{customer_email}```\\n'\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.messages[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5792624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_email', 'output_style']\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75dea81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "output_style = \"\"\"American English in a calm and respectful tone\"\"\"\n",
    "\n",
    "# No formatting needed for the template string. Observe that we did not use f-string here. Compare the following with prompt_to_llm above.\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {output_style}. \\\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    output_style=output_style,\n",
    "    customer_email=customer_email\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d70f9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Message >>>>>>>>>>>>>>> content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "for message in customer_messages:\n",
    "    print(f\"Message >>>>>>>>>>>>>>> {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "075f903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "# response = chat.invoke(\"What is 1+1?\")\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PREVIOUS TESTING CODE ^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eba61aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am quite frustrated that the lid of my blender came off and splattered my kitchen walls with smoothie. To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would really appreciate your assistance with this issue. Thank you.\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "189a2096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    output_style=service_style_pirate,\n",
    "    customer_email=service_reply)\n",
    "\n",
    "print(service_messages[0].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54121f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, me hearty! I be sorry to inform ye that the warranty be not coverin' the expenses fer cleanin' yer galley, as it seems ye may have misused yer blender by forgettin' to secure the lid afore settin' it to whirl. Aye, 'tis a bit of tough luck, indeed! Fair winds to ye, and may yer future adventures be less messy!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
